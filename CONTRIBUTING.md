# CONTRIBUTING.md ‚Äî Diretrizes de Desenvolvimento

Este guia define os padr√µes para o desenvolvimento do projeto `op_trader`, garantindo consist√™ncia, qualidade e escalabilidade nas contribui√ß√µes. Ele cobre codifica√ß√£o, organiza√ß√£o, testes, automa√ß√£o e logging para todas as fun√ß√µes que interagem com o c√≥digo.

---

## üìÅ Estrutura de Diret√≥rios

A estrutura de diret√≥rios do projeto √© organizada para separar c√≥digo, dados, modelos e logs:

```
op_trader/
‚îú‚îÄ‚îÄ audits/                   # Auditorias, evid√™ncias, relat√≥rios
‚îú‚îÄ‚îÄ config/                   # Configura√ß√µes por ambiente/componente
‚îú‚îÄ‚îÄ data/                     # Dados (raw, processed, features, external)
‚îú‚îÄ‚îÄ docs/                     # Documenta√ß√£o t√©cnica
‚îú‚îÄ‚îÄ infra/                    # Infraestrutura como c√≥digo (Docker, Kubernetes)
‚îú‚îÄ‚îÄ logs/                     # Logs estruturados (trades, evaluations, system)
‚îú‚îÄ‚îÄ models/                   # Modelos ML, checkpoints, artefatos
‚îú‚îÄ‚îÄ scripts/                  # Scripts de automa√ß√£o e CLI
‚îú‚îÄ‚îÄ src/                      # C√≥digo-fonte principal
‚îÇ   ‚îú‚îÄ‚îÄ agents/               # Agentes RL/ML
‚îÇ   ‚îú‚îÄ‚îÄ api/                  # APIs REST/GraphQL
‚îÇ   ‚îú‚îÄ‚îÄ connectors/           # Integra√ß√µes com brokers/APIs
‚îÇ   ‚îú‚îÄ‚îÄ core/                 # Orquestra√ß√£o, event bus, m√©tricas
‚îÇ   ‚îú‚îÄ‚îÄ data/                 # Ingest√£o, ETL, transforma√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ env/                  # Ambientes, execu√ß√£o, rewards, state
‚îÇ   ‚îú‚îÄ‚îÄ strategies/           # Estrat√©gias de trading
‚îÇ   ‚îú‚îÄ‚îÄ trade/                # Execu√ß√£o ao vivo/simula√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ train/                # Pipelines de treinamento
‚îÇ   ‚îú‚îÄ‚îÄ tune/                 # Tuning de hiperpar√¢metros
‚îÇ   ‚îî‚îÄ‚îÄ utils/                # Utilit√°rios
‚îú‚îÄ‚îÄ tests/                    # Testes funcionais e de integra√ß√£o
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ .github/workflows/ci.yml
‚îú‚îÄ‚îÄ .pre-commit-config.yaml
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ CONTRIBUTING.md
‚îú‚îÄ‚îÄ DEVELOPMENT_FLOW.md
‚îú‚îÄ‚îÄ REFACTORING_STEPS.md
‚îú‚îÄ‚îÄ CODE_OF_CONDUCT.md
‚îú‚îÄ‚îÄ SECURITY.md
‚îú‚îÄ‚îÄ CHANGELOG.md
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ environment.yml
‚îú‚îÄ‚îÄ docker-compose.yml
‚îî‚îÄ‚îÄ Makefile
```

---

## üóÇÔ∏è Conven√ß√£o Oficial ‚Äî Tabelas de Refer√™ncia, Desenvolvimento e Rastreamento

> **Esta conven√ß√£o √© obrigat√≥ria para todo fluxo de contribui√ß√£o, documenta√ß√£o e versionamento de SPECs, m√≥dulos e demandas do Op\_Trader.**

O projeto utiliza tr√™s arquivos de meta-documenta√ß√£o localizados em `docs/meta/` para garantir **rastreabilidade, status** e organiza√ß√£o de todas as especifica√ß√µes t√©cnicas e funcionais:

* [`REFERENCE_TABLE.md`](../docs/meta/REFERENCE_TABLE.md): Registro de tudo publicado/homologado, com link direto para o SPEC e status atualizado.
* [`DEVELOP_TABLE.md`](../docs/meta/DEVELOP_TABLE.md): Registro de tudo em planejamento, desenvolvimento ou revis√£o, incluindo previs√£o, respons√°vel e link do SPEC (quando aplic√°vel).
* [`TAGS_INDEX.md`](../docs/meta/TAGS_INDEX.md): √çndice oficial de todas as tags de status (codifica√ß√£o, revis√£o, homologa√ß√£o etc.), para uso consistente.

**Regras e obriga√ß√µes:**

* Sempre que houver nova demanda, altera√ß√£o, SPEC ou m√≥dulo: registre ou atualize imediatamente nas tabelas correspondentes.
* O campo de status deve estar sempre atualizado (‚â§ 24h √∫teis).
* Nenhuma tag pode ser usada sem antes ser definida no `TAGS_INDEX.md`.
* O rastreamento √© **audit√°vel** e obrigat√≥rio para merge, versionamento e auditoria.
* Mudan√ßas ou exce√ß√µes devem ser justificadas em logs de auditoria.

**Exemplo resumido do fluxo:**

1. Cria√ß√£o de nova SPEC ‚Üí registre em `DEVELOP_TABLE.md`.
2. Avan√ßou para homologa√ß√£o ‚Üí mova para `REFERENCE_TABLE.md` com status e tags adequados.
3. Surgiu nova tag ‚Üí cadastre significado em `TAGS_INDEX.md`.

Esta conven√ß√£o faz parte do fluxo de CI/CD, revis√£o e compliance documental do Op\_Trader.

---

## üîß Configura√ß√£o do Ambiente

### Requisitos do Sistema

* **Sistema Operacional**: Windows 10/11
* **Python**: 3.10.x (obrigat√≥rio para MetaTrader 5 API)
* **Conda**: Miniconda ou Anaconda
* **MetaTrader 5**: Instalado e configurado
* **CUDA**: Opcional, para acelera√ß√£o GPU
* **Docker**: Opcional, para containers
* **IDE Recomendada**: VSCode ou Spyder

### Configura√ß√£o Passo a Passo

1. **Instale o Conda** (se n√£o tiver):

   ```bash
   # Baixe e instale o Miniconda
   # https://docs.conda.io/en/latest/miniconda.html
   ```

2. **Clone o reposit√≥rio**:

   ```bash
   git clone <repository-url>
   cd op_trader
   ```

3. **Crie o ambiente**:

   ```bash
   conda env create -f environment.yml
   conda activate op_trader
   ```

4. **Verifique a instala√ß√£o**:

   ```bash
   python --version     # Deve retornar Python 3.10.x
   python -c "import pandas, numpy, tensorflow; print('Depend√™ncias OK')"
   ```

5. **Configure o IDE**:

   ```bash
   # Instale e configure seu editor favorito (VSCode recomendado para debugging Python)
   ```

6. **Configure vari√°veis de ambiente**:

   ```bash
   cp .env.example .env
   # Edite .env com suas configura√ß√µes (ex.: credenciais MT5)
   ```

### Solu√ß√£o de Problemas Comuns

| Problema                  | Solu√ß√£o                                                          |
| ------------------------- | ---------------------------------------------------------------- |
| **Erro de depend√™ncias**  | `conda clean -a && conda env create -f environment.yml --force`  |
| **Python n√£o encontrado** | Verificar se o ambiente est√° ativado: `conda activate op_trader` |
| **Import errors**         | `pip install -r requirements.txt`                                |

---

## üìù Padr√µes de Codifica√ß√£o

### 1. Importa√ß√µes Absolutas

**Obrigat√≥rio**: Todo script em `src/` deve usar importa√ß√µes absolutas com path patching:

```python
import sys
from pathlib import Path

# Adiciona a raiz do projeto ao sys.path
root_dir = Path(__file__).resolve().parents[2]  # Ajuste conforme localiza√ß√£o
sys.path.append(str(root_dir))

# Importa√ß√µes absolutas
from src.utils.logging_utils import get_logger
from src.env.trading_env import TradingEnvironment
```

### 2. Estrutura de Script Padr√£o

```python
#!/usr/bin/env python3
"""
Descri√ß√£o do m√≥dulo.

Este m√≥dulo faz X, Y e Z.
Autor: Developers Team
Data: YYYY-MM-DD
"""

import sys
from pathlib import Path
import argparse

# Path setup
root_dir = Path(__file__).resolve().parents[2]
sys.path.append(str(root_dir))

# Imports
from src.utils.logging_utils import get_logger

def main():
    """Fun√ß√£o principal do script."""
    parser = argparse.ArgumentParser(description="Descri√ß√£o do script")
    parser.add_argument("--debug", action="store_true", 
                       help="Ativa modo debug com logs detalhados")
    args = parser.parse_args()
    
    logger = get_logger(__name__, debug=args.debug)
    logger.info("Iniciando script...")
    
    try:
        # L√≥gica principal aqui
        pass
    except Exception as e:
        logger.error(f"Erro na execu√ß√£o: {e}")
        if args.debug:
            logger.exception("Stacktrace completo:")
        return 1
    
    logger.info("Script finalizado com sucesso.")
    return 0

if __name__ == "__main__":
    sys.exit(main())
```

### 3. Estilo de C√≥digo

- **Siga PEP 8** rigorosamente
- **Use type hints**:
  ```python
  def process_data(data: pd.DataFrame, symbol: str) -> pd.DataFrame:
  ```
- **Docstrings no formato Google**:
  ```python
  def calculate_rsi(prices: pd.Series, period: int = 14) -> pd.Series:
      """Calcula o RSI (Relative Strength Index).

      Args:
          prices (pd.Series): S√©rie de pre√ßos de fechamento.
          period (int, optional): Per√≠odo para c√°lculo. Defaults to 14.

      Returns:
          pd.Series: Valores do RSI.

      Raises:
          ValueError: Se o per√≠odo for menor que 1.
      """
  ```

### 4. Conven√ß√µes de Nomenclatura

| Tipo | Conven√ß√£o | Exemplo |
|------|-----------|---------|
| **Vari√°veis** | snake_case | `market_data`, `rsi_values` |
| **Fun√ß√µes** | snake_case | `calculate_indicators()` |
| **Classes** | PascalCase | `TradingEnvironment` |
| **Constantes** | UPPER_SNAKE_CASE | `MAX_POSITIONS`, `DEFAULT_TIMEFRAME` |
| **Arquivos** | snake_case | `data_collector.py` |
| **Diret√≥rios** | snake_case | `env_libs`, `reward_components` |

---

## üöÄ Execu√ß√£o de Scripts

### 1. Flag --debug Obrigat√≥ria

Todos os scripts execut√°veis devem implementar:

```python
parser = argparse.ArgumentParser(description="Descri√ß√£o do script")
parser.add_argument("--debug", action="store_true", 
                   help="Ativa modo debug com logs detalhados")
parser.add_argument("--symbol", type=str, default="EURUSD",
                   help="S√≠mbolo para processar")
parser.add_argument("--timeframe", type=str, default="M5",
                   help="Timeframe dos dados")
args = parser.parse_args()
```

### 2. Comportamento por Modo

#### Modo Normal (sem --debug):
- Logs n√≠vel `INFO`
- Erros tratados com `logger.error`
- Execu√ß√£o n√£o interrompida por erros n√£o-cr√≠ticos
- Sa√≠da limpa e profissional

#### Modo Debug (com --debug):
- Logs n√≠vel `DEBUG`
- Stacktraces completos com `logger.exception`
- Arquivos extras salvos (m√©tricas detalhadas, logs brutos)
- Informa√ß√µes detalhadas de performance

# Execu√ß√£o em modo debug
python src/trade/trade_executor.py --debug --symbol EURUSD --timeframe M5

# Execu√ß√£o em modo live (aten√ß√£o!)
python src/trade/trade_executor.py --live --symbol EURUSD --timeframe M5

Todos os scripts execut√°veis devem implementar pelo menos:
- `--debug`: Ativa modo de logs detalhados.
- `--live`: Executa no modo operacional real (aten√ß√£o, risco financeiro real).
- `--symbol`, `--timeframe`, etc.

### 3. Exemplos de Execu√ß√£o

```bash
# Modo normal
python src/data/data_collector.py --symbol EURUSD --timeframe M5

# Modo debug
python src/train/ppo/ppo_trainer.py --debug --symbol GBPUSD

# Com m√∫ltiplos par√¢metros
python src/trade/backtest_runner.py --debug --start-date 2024-01-01 --end-date 2024-12-31
```

---

## üìä Sistema de Logging

### 1. Configura√ß√£o Padr√£o

Use sempre o logger configurado em `src/utils/logger_template.py`:

```python
from src.utils.logging_utils import get_logger

# No in√≠cio da fun√ß√£o main()
logger = get_logger(__name__, debug=args.debug)
```

### 2. N√≠veis de Log e Cores

| N√≠vel | Cor | Uso | Exemplo |
|-------|-----|-----|---------|
| **DEBUG** | Cyan | Detalhes t√©cnicos | `logger.debug(f"Processando {len(data)} registros")` |
| **INFO** | Green | Informa√ß√µes gerais | `logger.info("Modelo treinado com sucesso")` |
| **WARNING** | Yellow | Alertas n√£o-cr√≠ticos | `logger.warning("Dados incompletos para per√≠odo")` |
| **ERROR** | Red | Erros recuper√°veis | `logger.error("Falha na conex√£o, tentando novamente")` |
| **CRITICAL** | Bold Red | Erros fatais | `logger.critical("Sistema n√£o pode continuar")` |

### 3. Integra√ß√£o com tqdm

Para loops com barra de progresso:

```python
from tqdm import tqdm

for i in tqdm(range(1000), desc="Processando dados"):
    # Sua l√≥gica aqui
    
    # Para logs durante o loop, use tqdm.write()
    if i % 100 == 0:
        tqdm.write(f"Checkpoint: {i}/1000 processados")
```

### 4. Logging em Classes

```python
class DataProcessor:
    def __init__(self, debug: bool = False):
        self.logger = get_logger(self.__class__.__name__, debug=debug)
    
    def process(self, data: pd.DataFrame) -> pd.DataFrame:
        self.logger.info(f"Processando {len(data)} registros")
        # ... l√≥gica ...
        self.logger.debug(f"Mem√≥ria utilizada: {data.memory_usage().sum()} bytes")
        return processed_data
```

---
## üß™ Testes de Funcionalidade

### 1. Estrutura de Testes

```
tests/
‚îú‚îÄ‚îÄ unit/                    # Testes de funcionalidade por m√≥dulo
‚îÇ   ‚îú‚îÄ‚îÄ test_data_processor.py
‚îÇ   ‚îú‚îÄ‚îÄ test_trading_env.py
‚îÇ   ‚îî‚îÄ‚îÄ test_rewards.py
‚îú‚îÄ‚îÄ integration/             # Testes de funcionalidade integrada
‚îÇ   ‚îú‚îÄ‚îÄ test_ppo_training.py
‚îÇ   ‚îî‚îÄ‚îÄ test_full_pipeline.py
‚îú‚îÄ‚îÄ fixtures/                # Dados de teste
‚îÇ   ‚îú‚îÄ‚îÄ sample_data.csv
‚îÇ   ‚îî‚îÄ‚îÄ mock_responses.json
‚îú‚îÄ‚îÄ logs/                    # Logs gerados pelos testes
‚îÇ   ‚îú‚îÄ‚îÄ test_logs.log
‚îÇ   ‚îî‚îÄ‚îÄ test_results/
‚îî‚îÄ‚îÄ conftest.py             # Configura√ß√µes pytest
```

### 2. Padr√µes de Teste Funcional

```python
import pytest
import pandas as pd
import os
import tempfile
from pathlib import Path
from unittest.mock import Mock, patch
import logging

from src.data.data_processor import DataProcessor

class TestDataProcessor:
    
    @pytest.fixture
    def temp_logs_dir(self):
        """Cria diret√≥rio tempor√°rio para logs de teste."""
        with tempfile.TemporaryDirectory() as temp_dir:
            logs_dir = os.path.join(temp_dir, "logs")
            os.makedirs(logs_dir, exist_ok=True)
            yield logs_dir
    
    @pytest.fixture
    def sample_market_data(self):
        """Dados de mercado reais para testes."""
        return pd.DataFrame({
            'datetime': pd.date_range('2024-01-01', periods=1000, freq='5min'),
            'open': [1.1000 + i*0.0001 for i in range(1000)],
            'high': [1.1015 + i*0.0001 for i in range(1000)],
            'low': [0.9995 + i*0.0001 for i in range(1000)],
            'close': [1.1010 + i*0.0001 for i in range(1000)],
            'volume': [1000 + i*10 for i in range(1000)]
        })
    
    def test_complete_data_processing_functionality(self, sample_market_data, temp_logs_dir):
        """Testa funcionalidade completa do processamento de dados."""
        # Configurar processor com logging real
        processor = DataProcessor(
            symbol="EURUSD", 
            timeframe="M5",
            debug=True,
            logs_dir=temp_logs_dir
        )
        
        # Testar processamento completo
        result = processor.process(sample_market_data)
        
        # Verificar funcionalidades b√°sicas
        assert isinstance(result, pd.DataFrame)
        assert len(result) == len(sample_market_data)
        
        # Verificar c√°lculos de indicadores t√©cnicos
        assert 'rsi' in result.columns
        assert 'sma_20' in result.columns
        assert 'ema_12' in result.columns
        
        # Verificar valores dos c√°lculos
        assert result['rsi'].min() >= 0
        assert result['rsi'].max() <= 100
        assert not result['sma_20'].isna().all()
        
        # Verificar logs foram criados
        log_files = list(Path(temp_logs_dir).glob("*.log"))
        assert len(log_files) > 0
        
        # Verificar conte√∫do dos logs
        with open(log_files[0], 'r') as f:
            log_content = f.read()
            assert "Processando 1000 registros" in log_content
            assert "Calculando indicadores t√©cnicos" in log_content
            assert "Processamento conclu√≠do" in log_content
    
    def test_error_handling_and_logging(self, temp_logs_dir):
        """Testa tratamento de erros e logging de exce√ß√µes."""
        processor = DataProcessor(
            symbol="INVALID", 
            timeframe="M5",
            debug=True,
            logs_dir=temp_logs_dir
        )
        
        # Testar dados vazios
        empty_df = pd.DataFrame()
        
        with pytest.raises(ValueError, match="Dados vazios n√£o podem ser processados"):
            processor.process(empty_df)
        
        # Verificar erro foi logado
        log_files = list(Path(temp_logs_dir).glob("*.log"))
        with open(log_files[0], 'r') as f:
            log_content = f.read()
            assert "ERROR" in log_content
            assert "Dados vazios n√£o podem ser processados" in log_content
    
    def test_debug_mode_functionality(self, sample_market_data, temp_logs_dir):
        """Testa funcionalidade espec√≠fica do modo debug."""
        # Modo debug ativado
        processor_debug = DataProcessor(
            symbol="EURUSD", 
            timeframe="M5",
            debug=True,
            logs_dir=temp_logs_dir
        )
        
        result_debug = processor_debug.process(sample_market_data)
        
        # Verificar arquivos extras salvos em modo debug
        debug_files = list(Path(temp_logs_dir).glob("*debug*"))
        assert len(debug_files) > 0
        
        # Verificar logs detalhados
        log_files = list(Path(temp_logs_dir).glob("*.log"))
        with open(log_files[0], 'r') as f:
            log_content = f.read()
            assert "DEBUG" in log_content
            assert "Mem√≥ria utilizada:" in log_content
            assert "Performance metrics:" in log_content
    
    def test_file_saving_functionality(self, sample_market_data, temp_logs_dir):
        """Testa funcionalidade de salvamento de arquivos."""
        processor = DataProcessor(
            symbol="EURUSD", 
            timeframe="M5",
            output_dir=temp_logs_dir
        )
        
        result = processor.process_and_save(sample_market_data)
        
        # Verificar arquivo foi salvo
        saved_files = list(Path(temp_logs_dir).glob("*processed*.csv"))
        assert len(saved_files) == 1
        
        # Verificar conte√∫do do arquivo salvo
        saved_data = pd.read_csv(saved_files[0])
        assert len(saved_data) == len(result)
        assert list(saved_data.columns) == list(result.columns)
        
        # Verificar nomenclatura do arquivo
        filename = saved_files[0].name
        assert "EURUSD" in filename
        assert "M5" in filename
        assert "processed" in filename
    
    def test_calculation_accuracy(self, sample_market_data):
        """Testa precis√£o dos c√°lculos matem√°ticos."""
        processor = DataProcessor()
        result = processor.process(sample_market_data)
        
        # Testar c√°lculo do RSI manualmente
        price_changes = sample_market_data['close'].diff()
        gains = price_changes.where(price_changes > 0, 0)
        losses = -price_changes.where(price_changes < 0, 0)
        
        avg_gain = gains.rolling(window=14).mean()
        avg_loss = losses.rolling(window=14).mean()
        rs = avg_gain / avg_loss
        expected_rsi = 100 - (100 / (1 + rs))
        
        # Comparar com resultado do processor (toler√¢ncia para arredondamento)
        pd.testing.assert_series_equal(
            result['rsi'].dropna(), 
            expected_rsi.dropna(), 
            check_names=False,
            rtol=1e-3
        )
```

### 3. Testes de Sistema Completo

```python
class TestTradingEnvironment:
    
    def test_complete_trading_simulation(self, sample_market_data, temp_logs_dir):
        """Testa simula√ß√£o completa de trading."""
        from src.env.trading_env import TradingEnvironment
        
        env = TradingEnvironment(
            data=sample_market_data,
            symbol="EURUSD",
            initial_balance=10000,
            debug=True,
            logs_dir=temp_logs_dir
        )
        
        # Simular epis√≥dio completo
        state = env.reset()
        total_reward = 0
        actions_taken = []
        
        for step in range(100):
            # A√ß√£o aleat√≥ria para teste
            action = env.action_space.sample()
            actions_taken.append(action)
            
            state, reward, done, info = env.step(action)
            total_reward += reward
            
            if done:
                break
        
        # Verificar funcionalidades
        assert len(actions_taken) > 0
        assert isinstance(total_reward, (int, float))
        assert env.current_balance != env.initial_balance  # Alguma atividade ocorreu
        
        # Verificar logs de trades
        trade_logs = list(Path(temp_logs_dir).glob("*trades*.csv"))
        assert len(trade_logs) > 0
        
        trades_df = pd.read_csv(trade_logs[0])
        assert 'action' in trades_df.columns
        assert 'reward' in trades_df.columns
        assert 'balance' in trades_df.columns
    
    def test_reward_calculation_functionality(self, sample_market_data):
        """Testa funcionalidade de c√°lculo de recompensas."""
        from src.env.rewards import RewardCalculator
        
        calculator = RewardCalculator(risk_penalty=0.1, drawdown_penalty=0.2)
        
        # Simular trade
        entry_price = 1.1000
        exit_price = 1.1020
        position_size = 1.0
        trade_duration = 10
        
        reward = calculator.calculate_trade_reward(
            entry_price=entry_price,
            exit_price=exit_price,
            position_size=position_size,
            trade_duration=trade_duration,
            action_type="buy"
        )
        
        # Verificar c√°lculo
        expected_profit = (exit_price - entry_price) * position_size
        assert reward > 0  # Trade lucrativo
        assert isinstance(reward, (int, float))
        
        # Testar trade perdedor
        losing_reward = calculator.calculate_trade_reward(
            entry_price=entry_price,
            exit_price=1.0980,  # Pre√ßo menor
            position_size=position_size,
            trade_duration=trade_duration,
            action_type="buy"
        )
        
        assert losing_reward < 0  # Trade com perda
```

### 4. Testes de Integra√ß√£o com APIs

```python
class TestDataCollection:
    
    @patch('src.connectors.mt5_connector.MetaTrader5')
    def test_real_data_collection_simulation(self, mock_mt5, temp_logs_dir):
        """Testa coleta de dados simulando conex√£o real."""
        from src.data.data_collector import DataCollector
        
        # Mock da resposta do MT5
        mock_data = pd.DataFrame({
            'time': [1640995200 + i*300 for i in range(100)],  # timestamps
            'open': [1.1000 + i*0.0001 for i in range(100)],
            'high': [1.1015 + i*0.0001 for i in range(100)],
            'low': [0.9995 + i*0.0001 for i in range(100)],
            'close': [1.1010 + i*0.0001 for i in range(100)],
            'volume': [1000 + i*10 for i in range(100)]
        })
        mock_mt5.copy_rates_range.return_value = mock_data.to_records(index=False)
        
        collector = DataCollector(
            symbol="EURUSD",
            timeframe="M5",
            debug=True,
            logs_dir=temp_logs_dir
        )
        
        # Testar coleta
        data = collector.collect_data(
            start_date="2024-01-01",
            end_date="2024-01-02"
        )
        
        # Verificar funcionalidade
        assert len(data) == 100
        assert 'datetime' in data.columns
        assert data['datetime'].dtype == 'datetime64[ns]'
        
        # Verificar logs de conex√£o
        log_files = list(Path(temp_logs_dir).glob("*.log"))
        with open(log_files[0], 'r') as f:
            log_content = f.read()
            assert "Conectando ao MT5" in log_content
            assert "Coletando dados para EURUSD" in log_content
            assert "Coleta finalizada: 100 registros" in log_content
```






### 5. Execu√ß√£o e Valida√ß√£o de Testes

```bash
# Executar todos os testes de funcionalidade
pytest tests/ -v --tb=short

# Testes com logs detalhados (debug)
pytest tests/ -v -s --log-cli-level=DEBUG

# Testar funcionalidade espec√≠fica
pytest tests/unit/test_data_processor.py::TestDataProcessor::test_complete_data_processing_functionality -v -s

# Validar que logs foram criados
pytest tests/ -v --capture=no

# Executar testes de integra√ß√£o (mais demorados)
pytest tests/integration/ -v --timeout=300
```

### 6. Requisitos de Funcionalidade

#### Testes Obrigat√≥rios para Cada M√≥dulo:

- **Funcionalidade Principal**: Testar o prop√≥sito principal do m√≥dulo
- **C√°lculos Matem√°ticos**: Validar precis√£o de f√≥rmulas e algoritmos  
- **Tratamento de Erros**: Simular cen√°rios de erro e verificar handling
- **Logging Real**: Verificar se logs s√£o salvos nos locais corretos
- **Modo Debug**: Testar funcionalidades extras do modo debug
- **Salvamento de Arquivos**: Verificar nomenclatura e conte√∫do de arquivos reais
- **Performance**: Medir tempo de execu√ß√£o para opera√ß√µes cr√≠ticas
- **Integra√ß√£o**: Testar intera√ß√£o com outros m√≥dulos

#### Crit√©rios de Aprova√ß√£o:

- **100% dos testes passando**: Sem exce√ß√µes
- **Logs gerados**: Todos os testes devem produzir logs reais
- **Arquivos salvos**: Verificar cria√ß√£o correta de arquivos reais de sa√≠da
- **C√°lculos validados**: Resultados matem√°ticos conferidos manualmente
- **Erros tratados**: Todos os cen√°rios de erro testados
- **Performance aceit√°vel**: Tempo de execu√ß√£o dentro dos limites

### 7. Debugging de Testes

```python
# Exemplo de teste com debugging avan√ßado
def test_with_detailed_debugging(self, sample_data, temp_logs_dir):
    """Teste com debugging detalhado para investiga√ß√£o."""
    
    # Configurar logging do teste
    test_logger = logging.getLogger('test_debug')
    handler = logging.FileHandler(os.path.join(temp_logs_dir, 'test_debug.log'))
    handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
    test_logger.addHandler(handler)
    test_logger.setLevel(logging.DEBUG)
    
    processor = DataProcessor(debug=True)
    
    # Log estado inicial
    test_logger.debug(f"Dados iniciais: {len(sample_data)} registros")
    test_logger.debug(f"Colunas: {list(sample_data.columns)}")
    
    # Executar com monitoramento
    import time
    start_time = time.time()
    
    result = processor.process(sample_data)
    
    end_time = time.time()
    test_logger.debug(f"Processamento levou {end_time - start_time:.2f} segundos")
    
    # Valida√ß√µes com logs detalhados
    for col in ['rsi', 'sma_20', 'ema_12']:
        if col in result.columns:
            null_count = result[col].isnull().sum()
            test_logger.debug(f"{col}: {null_count} valores nulos de {len(result)}")
            assert null_count < len(result) * 0.5, f"Muitos valores nulos em {col}"
```
---

---

## üìÑ Documenta√ß√£o T√©cnica e Templates

Toda documenta√ß√£o t√©cnica de novos m√≥dulos deve obrigatoriamente ser criada a partir do template oficial dispon√≠vel em:

- Especifica√ß√£o de m√≥dulos: [`docs/templates/SPEC_TEMPLATE.md`](docs/templates/SPEC_TEMPLATE.md)
- Template de testes de integra√ß√£o: [`docs/templates/INTEGRATION_TEST_TEMPLATE.md`](docs/templates/INTEGRATION_TEST_TEMPLATE.md)

> Ao criar ou atualizar um m√≥dulo, gere a especifica√ß√£o t√©cnica correspondente em `docs/specs/`, conforme o fluxo detalhado em `docs/flows/DEVELOPMENT_FLOW.md` e `docs/flows/REFACTORING_STEPS.md`.

## üíæ Salvamento de Arquivos

### 1. Padr√£o de Nomenclatura

**Formato geral**:
```
<categoria>/<subcategoria>/<prefixo>_<ativo>_<timeframe>_<tipo>_<per√≠odo>_<timestamp>.<extens√£o>
```

**Exemplos**:
```
# Dados
data/processed/features_EURUSD_M5_processed_2020-01-01-2025-05-31_20250531_143022.csv

# Modelos
models/buy/ppo_EURUSD_M5_long_20250531_143022/
‚îú‚îÄ‚îÄ model.zip
‚îú‚îÄ‚îÄ scaler.pkl
‚îú‚îÄ‚îÄ config.json
‚îî‚îÄ‚îÄ training_log.csv

# Logs
logs/trades/trades_EURUSD_M5_live_20250531.csv
logs/evaluations/backtest_EURUSD_M5_2024-01-01-2024-12-31_20250531_143022.csv
```

### 2. Utilit√°rio de Salvamento

```python
from src.utils.file_saver import (
    get_timestamp, 
    build_filename, 
    save_dataframe,
    create_model_directory
)

# Exemplo de uso
timestamp = get_timestamp()

# Para DataFrames
filename = build_filename(
    prefix="data/processed",
    suffix="features",
    asset="EURUSD",
    timeframe="M5",
    period="2024-01-01_2024-12-31",
    timestamp=timestamp,
    extension="csv"
)
save_dataframe(df, filename)

# Para modelos
model_dir = create_model_directory(
    category="buy",  # buy, sell, both
    model_type="ppo",
    asset="EURUSD",
    timeframe="M5",
    timestamp=timestamp
)
```

### 3. Estrutura de Lotes (.zip)

Quando enviar m√∫ltiplos arquivos:

```
modelo_completo_EURUSD_M5_20250531_143022.zip
‚îú‚îÄ‚îÄ README.md                    # Instru√ß√µes de uso
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ ppo_long.zip
‚îÇ   ‚îú‚îÄ‚îÄ ppo_short.zip
‚îÇ   ‚îî‚îÄ‚îÄ mlp_decisor.pkl
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ training_data.csv
‚îÇ   ‚îî‚îÄ‚îÄ validation_data.csv
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ model_config.json
‚îî‚îÄ‚îÄ logs/
    ‚îî‚îÄ‚îÄ training_metrics.csv
```

**Conte√∫do do README.md no .zip**:
```markdown
# Modelo Op_Trader - EURUSD M5

## Arquivos Inclu√≠dos
- `models/`: Modelos treinados (PPO Long/Short + MLP)
- `data/`: Dados de treinamento e valida√ß√£o
- `config/`: Configura√ß√µes utilizadas
- `logs/`: M√©tricas de treinamento

## Como Usar
1. Extrair arquivos na pasta `op_trader/models/`
2. Executar: `python src/trade/load_model.py --model-dir models/buy/ppo_EURUSD_M5_20250531_143022`

## M√©tricas de Performance
- Sharpe Ratio: 1.85
- Max Drawdown: 3.2%
- Win Rate: 67.3%
```

---

## ü§ñ Machine Learning e Dados

### 1. Gest√£o de Datasets

```python
# Estrutura padr√£o para datasets
class DatasetManager:
    def __init__(self, symbol: str, timeframe: str):
        self.symbol = symbol
        self.timeframe = timeframe
        self.logger = get_logger(self.__class__.__name__)
    
    def load_raw_data(self, start_date: str, end_date: str) -> pd.DataFrame:
        """Carrega dados brutos."""
        filename = f"data/raw/{self.symbol}_{self.timeframe}_raw_{start_date}_{end_date}.csv"
        self.logger.info(f"Carregando dados de {filename}")
        return pd.read_csv(filename)
    
    def save_processed_data(self, data: pd.DataFrame, suffix: str = "processed") -> str:
        """Salva dados processados."""
        timestamp = get_timestamp()
        filename = build_filename(
            prefix="data/processed",
            suffix=suffix,
            asset=self.symbol,
            timeframe=self.timeframe,
            timestamp=timestamp,
            extension="csv"
        )
        save_dataframe(data, filename)
        return filename
```

### 2. Versionamento de Modelos

```python
class ModelManager:
    def __init__(self, model_type: str, symbol: str, timeframe: str):
        self.model_type = model_type  # ppo_long, ppo_short, mlp_decisor
        self.symbol = symbol
        self.timeframe = timeframe
        self.logger = get_logger(self.__class__.__name__)
    
    def save_model(self, model, metrics: dict, config: dict) -> str:
        """Salva modelo com metadados."""
        timestamp = get_timestamp()
        model_dir = create_model_directory(
            category=self._get_category(),
            model_type=self.model_type,
            asset=self.symbol,
            timeframe=self.timeframe,
            timestamp=timestamp
        )
        
        # Salvar modelo
        model.save(f"{model_dir}/model.zip")
        
        # Salvar metadados
        metadata = {
            "symbol": self.symbol,
            "timeframe": self.timeframe,
            "model_type": self.model_type,
            "timestamp": timestamp,
            "metrics": metrics,
            "config": config
        }
        
        with open(f"{model_dir}/metadata.json", 'w') as f:
            json.dump(metadata, f, indent=2)
        
        return model_dir
```

### 3. Otimiza√ß√£o com Optuna

```python
import optuna
from optuna.integration import TFKerasPruningCallback

def optimize_hyperparameters(symbol: str, timeframe: str, n_trials: int = 100):
    """Otimiza hiperpar√¢metros usando Optuna."""
    
    def objective(trial):
        # Sugerir hiperpar√¢metros
        learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)
        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])
        n_steps = trial.suggest_categorical('n_steps', [1024, 2048, 4096])
        
        # Treinar modelo com hiperpar√¢metros
        model = create_ppo_model(learning_rate, batch_size, n_steps)
        metrics = train_model(model)
        
        return metrics['sharpe_ratio']  # Objetivo a maximizar
    
    # Criar estudo
    study = optuna.create_study(direction='maximize')
    study.optimize(objective, n_trials=n_trials, callbacks=[optuna_progress_callback])
    
    return study.best_params
```

---

## üîÑ Automa√ß√£o e DevOps

### 1. GitHub Actions Workflow

```yaml
# .github/workflows/ci.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: windows-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Miniconda
      uses: conda-incubator/setup-miniconda@v2
      with:
        activate-environment: op_trader
        environment-file: environment.yml
        python-version: 3.10
    
    - name: Lint with flake8
      shell: bash -l {0}
      run: |
        flake8 src/ --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 src/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    
    - name: Test with pytest
      shell: bash -l {0}
      run: |
        pytest tests/ --cov=src --cov-report=xml --cov-report=term
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
```

### 2. Scripts de Automa√ß√£o

```python
# src/utils/automation.py
def run_full_pipeline(symbol: str, timeframe: str, retrain: bool = False):
    """Executa pipeline completo de dados ‚Üí treinamento ‚Üí valida√ß√£o."""
    
    logger = get_logger(__name__)
    
    try:
        # 1. Coleta de dados
        logger.info("Iniciando coleta de dados...")
        run_command(f"python src/data/data_collector.py --symbol {symbol} --timeframe {timeframe}")
        
        # 2. Processamento
        logger.info("Processando dados...")
        run_command(f"python src/data/data_processor.py --symbol {symbol} --timeframe {timeframe}")
        
        # 3. Treinamento (se necess√°rio)
        if retrain:
            logger.info("Treinando modelos...")
            run_command(f"python src/train/ppo/ppo_trainer.py --symbol {symbol} --timeframe {timeframe}")
            run_command(f"python src/train/mlp/mlp_trainer.py --symbol {symbol} --timeframe {timeframe}")
        
        # 4. Valida√ß√£o
        logger.info("Executando valida√ß√£o...")
        run_command(f"python src/trade/backtest_runner.py --symbol {symbol} --timeframe {timeframe}")
        
        logger.info("Pipeline executado com sucesso!")
        
    except Exception as e:
        logger.error(f"Erro no pipeline: {e}")
        raise
```

---

## üìà Monitoramento e M√©tricas

### 1. Callback de Progresso

```python
# src/utils/callbacks.py
class TrainingProgressCallback:
    def __init__(self, total_steps: int, save_freq: int = 1000):
        self.pbar = tqdm(total=total_steps, desc="Treinamento")
        self.save_freq = save_freq
        self.step_count = 0
        self.metrics_history = []
    
    def on_step(self, metrics: dict):
        self.step_count += 1
        self.pbar.update(1)
        
        # Atualizar descri√ß√£o com m√©tricas
        self.pbar.set_postfix({
            'reward': f"{metrics.get('reward', 0):.3f}",
            'loss': f"{metrics.get('loss', 0):.3f}"
        })
        
        # Salvar checkpoint
        if self.step_count % self.save_freq == 0:
            self.save_checkpoint(metrics)
    
    def save_checkpoint(self, metrics: dict):
        """Salva checkpoint do treinamento."""
        checkpoint_data = {
            'step': self.step_count,
            'metrics': metrics,
            'timestamp': get_timestamp()
        }
        self.metrics_history.append(checkpoint_data)
```

### 2. Monitor de Sistema

```python
# src/utils/system_monitor.py
import psutil
import time

class SystemMonitor:
    def __init__(self, log_interval: int = 60):
        self.log_interval = log_interval
        self.logger = get_logger(self.__class__.__name__)
        self.running = False
    
    def start_monitoring(self):
        """Inicia monitoramento do sistema."""
        self.running = True
        
        while self.running:
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            
            self.logger.info(f"CPU: {cpu_percent}% | "
                           f"RAM: {memory.percent}% | "
                           f"Disk: {disk.percent}%")
            
            # Alertas
            if cpu_percent > 90:
                self.logger.warning(f"CPU alta: {cpu_percent}%")
            if memory.percent > 85:
                self.logger.warning(f"Mem√≥ria alta: {memory.percent}%")
            
            time.sleep(self.log_interval)
```

---

## ‚úÖ Checklist de Qualidade

### Antes de Fazer Commit

- [ ] **C√≥digo segue PEP 8** (verificar com `flake8`)
- [ ] **Imports absolutos** configurados corretamente
- [ ] **Flag --debug** implementada em scripts execut√°veis
- [ ] **Docstrings** no formato Google para fun√ß√µes p√∫blicas
- [ ] **Type hints** em fun√ß√µes principais
- [ ] **Testes funcionais** escritos para toda nova funcionalidade
- [ ] **N√£o perseguir cobertura cega:** cobertura alta √© desej√°vel, mas nunca mais importante que a utilidade dos testes
- [ ] **Logs apropriados** em todos os n√≠veis
- [ ] **Tratamento de erros** implementado
- [ ] **Nomenclatura consistente** de arquivos e vari√°veis
- [ ] **Veja tamb√©m o `DEVELOPMENT_FLOW.md`** para fluxo macro de desenvolvimento.

### Antes de Fazer Deploy

- [ ] **Todos os testes passando**
- [ ] **Linting sem erros cr√≠ticos**
- [ ] **Documenta√ß√£o atualizada**
- [ ] **Configura√ß√µes validadas**
- [ ] **Backup dos modelos** atual
- [ ] **Logs de sistema** funcionais
- [ ] **Monitoramento** configurado
- [ ] **Rollback plan** definido

---

## üîß Ferramentas e Depend√™ncias

### Core Dependencies
```yaml
# environment.yml (principais)
dependencies:
  - python=3.10
  - pandas>=1.5.0
  - numpy>=1.24.0
  - tensorflow>=2.12.0
  - stable-baselines3>=2.0.0
  - optuna>=3.0.0
  - colorlog>=6.7.0
  - tqdm>=4.64.0
  - pytest>=7.0.0
  - pytest-cov>=4.0.0
  - flake8>=6.0.0
```

### Development Tools
```bash
# Linting
flake8 src/ --max-line-length=127 --extend-ignore=E203,W503

# Testing
pytest tests/ --cov=src --cov-report=html  # Cobertura √© acompanhada, mas n√£o obrigat√≥ria


# Type checking (opcional)
mypy src/ --ignore-missing-imports

# Formata√ß√£o (opcional)
black src/ --line-length=127
```

---

## üìñ Documenta√ß√£o Adicional

- **API Reference**: `docs/api_reference.md`
- **User Guide**: `docs/user_guide.md`
- **Architecture**: `docs/architecture.md`
- **Troubleshooting**: `docs/troubleshooting.md`
- **Examples**: `docs/examples/`

---

## üÜò Suporte e Solu√ß√£o de Problemas

### Problemas Comuns

1. **Import Error**: Verificar se `sys.path` est√° configurado corretamente
2. **Conda Environment**: Recriar ambiente com `conda env create -f environment.yml --force`
3. **Memory Issues**: Monitorar uso com `SystemMonitor`
4. **Test Failures**: Executar com `pytest -v -s` para debug detalhado

### Contato

- **Issues**: Usar GitHub Issues para bugs e features
- **Discussions**: GitHub Discussions para d√∫vidas
- **Documentation**: Contribuir via Pull Request

---

## ‚ö†Ô∏è Aviso

**Este sistema opera com dinheiro real. Teste em modo `--debug` antes de usar `--live`. O uso √© por sua conta e risco.**

*Este guia √© atualizado regularmente. √öltima revis√£o: 06/06/2025